{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "\n",
      "from ml.apps.skin.timeseries import *\n",
      "from ml.apps.skin.timeseries_old import *\n",
      "from ml.simple.table import *\n",
      "from ml.datasets.skin import SkinDataset\n",
      "from ml.common.test import check_gradient, check_directional_gradient\n",
      "from climin.gd import GradientDescent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "force_min = 0\n",
      "force_step = 0.1\n",
      "force_max = 25\n",
      "skin_min = 0\n",
      "skin_step = 0.02\n",
      "skin_max = 2\n",
      "\n",
      "ds = SkinDataset(\"raising_small\")\n",
      "ds.print_statistics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dataset Z:\\dev\\indentor\\indentor\\apps\\out\\raising_small.skn:\n",
        "     taxel          train   validation   test\n",
        "     1,1            800     100          100\n",
        "     3,2            785      98           98\n",
        "Avg. datapoints per record: 2433"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sampling interval:          0.01 s\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "taxel = (1,1)\n",
      "n_curves = None\n",
      "\n",
      "X, Z = build_nextstep_data(ds, 'train', taxel, n_curves=n_curves)\n",
      "print \"Trainingset size: %d steps\" % X.shape[1]\n",
      "\n",
      "Xval, Zval = build_nextstep_data(ds, 'validation', taxel)\n",
      "print \"Validationset size: %d steps\" % Xval.shape[1]\n",
      "\n",
      "Xtst, Ztst = build_nextstep_data(ds, 'test', taxel)\n",
      "print \"Testset size: %d steps\" % Xtst.shape[1]\n",
      "\n",
      "test_curves = ds.record('test', (1,1), range(20))\n",
      "test_force, test_skin, test_valid = build_multicurve(test_curves)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trainingset size: 1945207 steps\n",
        "Validationset size: 246044 steps"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Testset size: 244160 steps"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Multistep gradient profiling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curve = ds.record('train', (1,1))\n",
      "force, skin, valid = build_multicurve(curve)\n",
      "\n",
      "print \"Number of steps:    \", force.shape[0]\n",
      "print \"Number of samples:  \", force.shape[1]\n",
      "\n",
      "tr = SmoothTableRegression([force_min, skin_min], \n",
      "                           [force_step, skin_step], \n",
      "                           [force_max, skin_max])\n",
      "tr.weights = np.random.random(size=tr.weights.shape)\n",
      "tr.sparse = True\n",
      "print \"Number of weights: %d\" % tr.weight_matrix.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of steps:     3018\n",
        "Number of samples:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 800\n",
        "Number of weights: 26416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit skin_p = predict_multistep(tr.predict, force, valid, skin[0, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 2.35 s per loop\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%prun -s cumulative skin_p = predict_multistep(tr.predict, force, valid, skin[0, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(5,5)\n",
      "\n",
      "force_big = np.tile(force, (1, 10))\n",
      "skin_big = np.tile(skin, (1, 10))\n",
      "valid_big = np.tile(valid, (1, 10))\n",
      "\n",
      "steps = 20\n",
      "samples = range(0, 8000, 100)\n",
      "times = []\n",
      "for smpls in samples:\n",
      "    st = time.time()\n",
      "    skin_p = predict_multistep(tr.predict, force_big[0:steps, 0:smpls], valid_big[0:steps, 0:smpls], skin_big[0, 0:smpls])\n",
      "    et = time.time()\n",
      "    times.append(et-st)\n",
      "    \n",
      "plot(samples, times)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[<matplotlib.lines.Line2D at 0x20572080>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAE4CAYAAAA9w7rPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKImIbGBQEhHZwKAkIrKBQUlEZMP/A2chztYG4q+tAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0xa293be0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_step = 0\n",
      "test_steps = 50\n",
      "\n",
      "f = force[start_step:start_step+test_steps, :]\n",
      "s = skin[start_step:start_step+test_steps, :]\n",
      "v = valid[start_step:start_step+test_steps, :]\n",
      "\n",
      "%timeit multistep_predict(tr.predict, f, v, s[0, :])\n",
      "%timeit multistep_gradient(tr.predict_and_gradient, f, s, v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 30.1 ms per loop\n",
        "1 loops, best of 3: 464 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "start_step = 2000\n",
      "test_steps = 50\n",
      "\n",
      "f = force[start_step:start_step+test_steps, :]\n",
      "s = skin[start_step:start_step+test_steps, :]\n",
      "v = valid[start_step:start_step+test_steps, :]\n",
      "\n",
      "%timeit multistep_predict(tr.predict, f, v, s[0, :])\n",
      "%timeit multistep_gradient(tr.predict_and_gradient, f, s, v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 30.3 ms per loop\n",
        "1 loops, best of 3: 446 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.count_nonzero(~v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "7199"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Multistep gradient verification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tr = SmoothTableRegression([0.4, 0.0], \n",
      "#                           [0.1, 0.1], \n",
      "#                           [0.6, 0.2])\n",
      "\n",
      "test_steps = 10\n",
      "test_samples = 1\n",
      "\n",
      "#print force[0:test_steps, 0:test_samples], skin[0:test_steps, 0:test_samples]\n",
      "\n",
      "gr_dense = multistep_gradient(tr.predict_and_gradient, force[0:test_steps, 0:test_samples], skin[0:test_steps, 0:test_samples], valid[0:test_steps, 0:test_samples])\n",
      "gr_sparse = multistep_gradient_sparse_mat(tr.predict_and_gradient, force[0:test_steps, 0:test_samples], skin[0:test_steps, 0:test_samples], valid[0:test_steps, 0:test_samples])\n",
      "\n",
      "gr_diff = gr_dense - gr_sparse\n",
      "diff = np.sum(np.abs(gr_diff))\n",
      "\n",
      "print \"dense gradient:\"\n",
      "print gr_dense\n",
      "print\n",
      "print \"sparse gradient:\"\n",
      "print gr_sparse\n",
      "print\n",
      "print \"difference:\"\n",
      "print gr_diff\n",
      "print \"sum:\", diff\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dense gradient:\n",
        "[ 0.  0.  0. ...,  0.  0.  0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sparse gradient:\n",
        "[ 0.  0.  0. ...,  0.  0.  0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "difference:\n",
        "[ 0.  0.  0. ...,  0.  0.  0.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sum:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr = SmoothTableRegression([force_min, skin_min], \n",
      "                           [2, 0.2], \n",
      "                           [force_max, skin_max])\n",
      "np.random.seed(100)\n",
      "tr.weights = np.random.random(size=tr.weights.shape)\n",
      "#tr.weights = np.zeros(tr._weights.shape)\n",
      "method = 1\n",
      "\n",
      "test_steps = 20\n",
      "test_samples = 30\n",
      "\n",
      "def func_wrapper(w):\n",
      "    tr.weights = w\n",
      "    skin_p = predict_multistep(tr.predict, force[0:test_steps, 0:test_samples], \n",
      "                               valid[0:test_steps, 0:test_samples], skin[0, 0:test_samples])\n",
      "    return multistep_error(skin_p, skin[0:test_steps, 0:test_samples], valid[0:test_steps, 0:test_samples])\n",
      "    \n",
      "def grad_wrapper(w):\n",
      "    tr.weights = w\n",
      "    if method == 1:\n",
      "        return multistep_gradient_sparse_mat(tr.predict_and_gradient, \n",
      "                                             force[0:test_steps, 0:test_samples], skin[0:test_steps, 0:test_samples], \n",
      "                                             valid[0:test_steps, 0:test_samples])\n",
      "    elif method == 2:\n",
      "        return multistep_gradient(tr.predict_and_gradient,\n",
      "                                  force[0:test_steps, 0:test_samples], skin[0:test_steps, 0:test_samples], \n",
      "                                  valid[0:test_steps, 0:test_samples])    \n",
      "    else:\n",
      "        return multistep_gradient_sparse(tr,\n",
      "                                         force[0:test_steps, 0:test_samples], skin[0:test_steps, 0:test_samples], \n",
      "                                         valid[0:test_steps, 0:test_samples])\n",
      "\n",
      "#print func_wrapper(tr._weights)\n",
      "#print grad_wrapper(tr._weights)\n",
      "\n",
      "check_gradient(func_wrapper, grad_wrapper, tr.weights, tolerance=1, always_output=False)\n",
      "\n",
      "#for i in range(tr.weights.size):\n",
      "#    print i\n",
      "#    direction = np.zeros(tr.weights.shape)\n",
      "#    direction[i] = 1\n",
      "#    check_directional_gradient(func_wrapper, grad_wrapper, tr.weights, direction=direction, always_output=False, tolerance=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}